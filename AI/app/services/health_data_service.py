# serviace/health_data_service.py
"""
ê±´ê°• ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ ì„œë¹„ìŠ¤ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
- ê±´ê°• ë°ì´í„° ìˆ˜ì§‘
- AIë¥¼ í™œìš©í•œ ê±´ê°• ë°ì´í„° ë¶„ì„
- ë‚´ë¶€/ì™¸ë¶€ AI ì„œë¹„ìŠ¤ í˜¸ì¶œ
- ê±´ê°• ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥

ì£¼ìš” í´ë˜ìŠ¤:
- HealthDataProcessor: ê±´ê°• ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ì„ ë‹´ë‹¹í•˜ëŠ” í•µì‹¬ í”„ë¡œì„¸ì„œ
"""

from fastapi import APIRouter, HTTPException, Query, Depends
from sqlalchemy.orm import Session, joinedload
from core.database import get_db
from models import Measure, Client, User, BodyComposition, BloodPressure, HeartRate, Schedule, WeeklyReport
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from openai import OpenAI
import json
import httpx
import time
from core.config import settings
from schemas.health_data import HealthDataResponse
import aiohttp  # ë°°ì¹˜ëª¨ë“œì—ì„œ ì„¸ì…˜ ì¬ì‚¬ìš©ìš©
from openai import AsyncOpenAI  # ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸




class HealthDataProcessor:


    def __init__(self, db: Session):
        self.db = db


        # ëª¨ë¸ ê²½ë¡œ (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
        self.model_path = os.getenv("BASE_MODEL_PATH", "/srv/models/base")
        self.adapter_path = os.getenv("ADAPTER_PATH", "/srv/models/mistral_lora_adapter")

        # ëª¨ë¸ ë¡œë”©
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
        base_model = AutoModelForCausalLM.from_pretrained(
            self.model_path,
            device_map="auto",
            torch_dtype=torch.float16  # ë˜ëŠ” bfloat16, í™˜ê²½ì— ë”°ë¼ ì¡°ì ˆ
        )
        self.model = PeftModel.from_pretrained(base_model, self.adapter_path)
        self.model.eval()  # í‰ê°€ ëª¨ë“œ

        # ë¹„ë™ê¸° OpenAI í´ë¼ì´ì–¸íŠ¸
        self.openai_client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)

         # ë°°ì¹˜ ì‘ì—…ìš© ì„¤ì •
        self.batch_mode = False
        self.aiohttp_session = None



    def set_batch_mode(self, enabled: bool, aiohttp_session: Optional[aiohttp.ClientSession] = None):
        """ë°°ì¹˜ ëª¨ë“œ ì„¤ì •"""
        self.batch_mode = enabled
        self.aiohttp_session = aiohttp_session



    async def collect_health_data(self, client_id: int, user_id: int) -> Dict:
        """ê±´ê°• ì¸¡ì • ë°ì´í„° ìˆ˜ì§‘"""
        today = datetime.now()
        start = today - timedelta(days=6)  # days ì˜¤íƒ€ ìˆ˜ì •

        # ë‚ ì§œ ë²”ìœ„ë¥¼ Epoch(ms)ë¡œ ë³€í™˜
        start_epoch = int(start.replace(hour=0, minute=0, second=0, microsecond=0).timestamp() * 1000)
        end_epoch = int((today - timedelta(days=1)).replace(hour=23, minute=59, second=59, microsecond=999000).timestamp() * 1000)

        # ì¡°íšŒ: ì›”~ê¸ˆ ë²”ìœ„ ë‚´ ì¸¡ì •
        measures = (
            self.db.query(Measure)
            .options(
                joinedload(Measure.body_composition),
                joinedload(Measure.blood_pressure),
                joinedload(Measure.heart_rate),
                joinedload(Measure.client)
            )
            .filter(
                Measure.user_id == user_id,
                Measure.client_id == client_id,
                Measure.date >= start_epoch,
                Measure.date <= end_epoch
            )
            .order_by(Measure.date.asc())
            .all()
        )

        # ë°ì´í„° í¬ë§· ë³€í™˜
        dm_list = []
        for measure in measures:
            bc = measure.body_composition
            bp = measure.blood_pressure
            hr = measure.heart_rate
            client = measure.client

            dm_item = {
                # ë‚ ì§œ
                "d": datetime.fromtimestamp(measure.date/1000).date().isoformat(),
                
                # body_composition ë°ì´í„° (None ì²´í¬)
                "bf": bc.bfp if bc else None,
                "mm": bc.smm if bc else None,
                "bw": bc.bfm if bc else None,  # ì‰¼í‘œ ëˆ„ë½ ìˆ˜ì •
                "prot": bc.protein if bc else None,
                "min": bc.mineral if bc else None,

                # client ë°ì´í„° (ì†ì„± ì ‘ê·¼ ë°©ì‹ ìˆ˜ì •)
                "wt": client.weight if client else None,
                "ht": client.height if client else None,

                # heart_rate ë°ì´í„°
                "hr": hr.bpm if hr else None,
                "o2": hr.oxygen if hr else None,

                # blood_pressure ë°ì´í„° (None ì²´í¬ ì¶”ê°€)
                "sys": bp.sbp if bp else None,
                "dia": bp.dbp if bp else None,
            }
            dm_list.append(dm_item)

        return {
            "ws": start.date().isoformat(),
            "we": (today - timedelta(days=1)).date().isoformat(),  # ë©”ì†Œë“œ í˜¸ì¶œ ìˆ˜ì •
            "dm": dm_list
        }
    


    

    async def call_internal_ai(self, health_data: Dict) -> Dict:
        """HuggingFace Mistral ëª¨ë¸(EC2ì— ì €ì¥ ì¤‘)ë¡œ ì§ì ‘ ì¶”ë¡ """

        prompt = {
            "input": (
                "### ì§ˆë¬¸:\n" + json.dumps(health_data, ensure_ascii=False) + 
                "\n### ì§€ì‹œì‚¬í•­:\n1) ì£¼ê°„ í‰ê· Â·ìµœì†ŒÂ·ìµœëŒ“ê°’ì„ **wsum** í•„ë“œì— ì‘ì„±í•˜ê³ \n"
                "2) í‰ê·  ëŒ€ë¹„ Â±2 % ì´ìƒ ë²—ì–´ë‚œ ê°’ì„ **anom** ë°°ì—´ì—\n"
                "   { \"d\": ë‚ ì§œ, \"m\": ì§€í‘œ, \"v\": ê°’, \"pct\": Â±ë³€ë™ë¥  } í˜•ì‹ìœ¼ë¡œ ê¸°ë¡í•˜ë©°\n"
                "3) **cmt.g** ì—ì„œ\n"
                "   - ì£¼ê°„ ì´í‰ í•œ ë¬¸ë‹¨ ì‘ì„±\n"
                "   - íŠ¹ì´ì‚¬í•­ ë‚ ì§œÂ·ì§€í‘œÂ·Â±% ìš”ì•½\n"
                "4) ë³€ë™ ì§€í‘œì— ë§ì¶° 3ê°€ì§€ **fd**(ì‹ë‹¨) ì¶”ì²œ:\n"
                "   Â· ì²´ì¤‘Â·ì²´ì§€ë°© â†‘ â‡’ ì €ì§€ë°© ë©”ë‰´\n"
                "   Â· í˜ˆì•• â†‘ â‡’ ì €ì—¼ ë©”ë‰´\n"
                "(ê·¸ ì™¸ í•„ë“œëŠ” ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”)\n### ë‹µë³€:\n"
            )
        }

        # ğŸ”¹ Tokenize & Model Inference
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)

        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=512,
                do_sample=False,
                temperature=0.7
            )

        output_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)

        # ğŸ”¹ JSON ë¶€ë¶„ë§Œ íŒŒì‹±
        try:
            json_part = output_text.strip()
            return json.loads(json_part)
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ì¶”ë¡  ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        
         # ë°°ì¹˜ ëª¨ë“œì—ì„œëŠ” ì„¸ì…˜ ì¬ì‚¬ìš©
        if self.batch_mode and self.aiohttp_session:
            async with self.aiohttp_session.post(
                self.internal_ai_url,
                json=input_payload,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                response.raise_for_status()
                return await response.json()
        else:
            # ë‹¨ì¼ ìš”ì²­ ëª¨ë“œ
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    self.internal_ai_url,
                    json=input_payload,
                    timeout=30.0
                )
                response.raise_for_status()
                return response.json()
        



    def clean_ai_output(self, ai_output: str) -> Dict:
        """AI output ì •ì œ"""
        try:
            # ë¬¸ìì—´ì´ ì•„ë‹Œ dictì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(ai_output, dict):
                return ai_output
                
            # JSON ë¬¸ìì—´ íŒŒì‹±
            if ai_output.startswith('"') and ai_output.endswith('"'):
                # JSON ë¬¸ìì—´ì´ ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ê²½ìš°
                ai_output = ai_output[1:-1]
                ai_output = ai_output.replace('\\"', '"')
            
            return json.loads(ai_output)
            
        except json.JSONDecodeError as e:
            raise HTTPException(status_code=500, detail=f"AI output íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        


    
    async def get_journal_data(self, client_id: int, user_id: int) -> List[Dict]:
        """ì¼ì§€ ë°ì´í„° ì¡°íšŒ"""
        today = datetime.now()
        start = today - timedelta(days=6)  # days ì˜¤íƒ€ ìˆ˜ì •

        # ë‚ ì§œ ë²”ìœ„ë¥¼ Epoch(ms)ë¡œ ë³€í™˜
        start_epoch = int(start.replace(hour=0, minute=0, second=0, microsecond=0).timestamp() * 1000)
        end_epoch = int((today - timedelta(days=1)).replace(hour=23, minute=59, second=59, microsecond=999000).timestamp() * 1000)

        schedules = (
            self.db.query(Schedule)
            .filter(
                Schedule.user_id == user_id,  
                Schedule.client_id == client_id,  
                Schedule.visited_date >= start_epoch,
                Schedule.visited_date <= end_epoch,
                Schedule.log_content.isnot(None)  # ì¼ì§€ê°€ ìˆëŠ” ê²ƒë§Œ
            )
            .order_by(Schedule.visited_date.asc())
            .all()
        )

        return [
            {
                "date": datetime.fromtimestamp(schedule.visited_date / 1000).date().isoformat(),
                "start_time": datetime.fromtimestamp(schedule.start_at / 1000).strftime("%H:%M") if schedule.start_at else None,
                "end_time": datetime.fromtimestamp(schedule.end_at / 1000).strftime("%H:%M") if schedule.end_at else None,
                "log_content": schedule.log_content or ""
            }
            for schedule in schedules
        ]
    




    def create_openai_prompt(self, ai_summary: Dict, journal_data: List) -> str:
        """OpenAI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # AI ìš”ì•½ ë°ì´í„° í¬ë§·íŒ…
        wsum = ai_summary.get("wsum", {})
        anomalies = ai_summary.get("anom", [])
        ai_comment = ai_summary.get("cmt", {}).get("g", "")
        food_suggestions = ai_summary.get("fd", [])  

        # ëŒë´„ ì¼ì§€ ë°ì´í„° í¬ë§·íŒ…
        journal_summary = ""
        if journal_data:
            journal_entries = []
            for entry in journal_data[:5]:
                date = entry.get('date', '')
                content = entry.get('log_content', '')
                journal_entries.append(f"{date}: {content}")
            journal_summary = " | ".join(journal_entries)

        input_data = {
        "wsum": wsum,
        "anom": anomalies,
        "ai_comment": ai_comment,
        "food": food_suggestions,
        "journal": journal_summary
        }   
        
        prompt = (
        "### ì§ˆë¬¸:\n" + json.dumps(input_data, ensure_ascii=False) + 
        "\n### ì§€ì‹œì‚¬í•­:\n1) **ai_comment**ì— ê±´ê°•ìƒíƒœ í‰ê°€ ì‘ì„± (500ì ì´í•˜)\n"
        "2) **food**ì— ì¶”ì²œìŒì‹ë³„ ì´ìœ  ì‘ì„± (dict í˜•íƒœ)\n"
        "3) **journal**ì— ëŒë´„ì¼ì§€ ìš”ì•½ ì‘ì„± (300ì ì´í•˜)\n"
        "(ê·¸ ì™¸ í•„ë“œëŠ” ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”)\n### ë‹µë³€:\n"
        )

        return prompt
        




    async def call_openai(self, ai_summary: Dict, journal_data: List) -> Dict:
        """OpenAI API í˜¸ì¶œ"""

        

        prompt = self.create_openai_prompt(ai_summary, journal_data)
        response = self.openai_client.chat.completions.create(
                                                                model="gpt-4o-mini",
                                                                messages=[{"role":"user","content":prompt}],
                                                                temperature=0.7 )
        openai_output = response.choices[0].message.content.strip()

        # JSON ì•ë’¤ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
        if "```json" in openai_output:
            openai_output = openai_output.split("```json")[1].split("```")[0].strip()
        elif "```" in openai_output:
            openai_output = openai_output.split("```")[1].strip()
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            result = json.loads(openai_output)
        except json.JSONDecodeError as e:
            raise HTTPException(status_code=500, detail=f"OpenAI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")

        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ["comment", "fd_explain", "summary"]
        missing_fields = [f for f in required_fields if f not in result]
        if missing_fields:
            raise ValueError(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {missing_fields}")
            
        return result
    

        
    def save_to_database(self, client_id: int, user_id: int, ai_summary: Dict, openai_result: Dict) -> int:
        """ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        # OpenAI ê²°ê³¼ì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
        # report_content = self._prepare_report_content(openai_result)
        # log_summary = openai_result.get('summary', ''
        # report_content ìƒì„± (JSON í˜•íƒœë¡œ ì €ì¥)
        report_content = {
            "ai_analysis": ai_summary,  # 1ì°¨ AI ê²°ê³¼ ì „ì²´
            "final_comment": openai_result.get('comment', ''),  # OpenAI ìµœì¢… ì½”ë©˜íŠ¸
            "food_explain": openai_result.get('fd_explain', {}),  # ì‹ë‹¨ ì„¤ëª…
            "created_at": int(time.time() * 1000),
            "version": "1.0"  # ìŠ¤í‚¤ë§ˆ ë²„ì „
        }

        # ìƒˆë¡œìš´ weekly_report ê°ì²´ ìƒì„±
        weekly_report = WeeklyReport(
            client_id=client_id,
            report_content=json.dumps(report_content, ensure_ascii=False),
            log_summary=openai_result.get('summary', ''),
            created_at=int(time.time() * 1000)  # millisecondsë¡œ ë³€í™˜ / bigintë¡œ ì €ì¥
        )

        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        self.db.add(weekly_report)
        self.db.commit()
        self.db.refresh(weekly_report)
        
        return weekly_report.report_id
    

    

    # def _prepare_report_content(self, openai_result: Dict) -> str:
    #     """OpenAI ê²°ê³¼ë¥¼ Text í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    #     report_parts = []
        
    #     # ì½”ë©˜íŠ¸ ì¶”ê°€
    #     if comment := openai_result.get('comment'):
    #         report_parts.append(f"## ì£¼ê°„ ê±´ê°• ìƒíƒœ ì¢…í•© í‰ê°€\n{comment}\n")
        
    #     # ì‹ë‹¨ ì„¤ëª… ì¶”ê°€
    #     if fd_explain := openai_result.get('fd_explain'):
    #         report_parts.append("## ì¶”ì²œ ì‹ë‹¨ ì„¤ëª…")
    #         for food, reason in fd_explain.items():
    #             report_parts.append(f"- **{food}**: {reason}")
    #         report_parts.append("")
        
    #     # ìš”ì•½ ì¶”ê°€
    #     if summary := openai_result.get('summary'):
    #         report_parts.append(f"## ì£¼ê°„ ëŒë´„ ìƒí™© ìš”ì•½\n{summary}")
        
    #     return "\n".join(report_parts)
