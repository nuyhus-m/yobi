
# serviace/health_data_service.py
"""
ê±´ê°• ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ ì„œë¹„ìŠ¤ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
- ê±´ê°• ë°ì´í„° ìˆ˜ì§‘
- AIë¥¼ í™œìš©í•œ ê±´ê°• ë°ì´í„° ë¶„ì„
- ë‚´ë¶€/ì™¸ë¶€ AI ì„œë¹„ìŠ¤ í˜¸ì¶œ
- ê±´ê°• ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥

ì£¼ìš” í´ë˜ìŠ¤:
- HealthDataProcessor: ê±´ê°• ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ì„ ë‹´ë‹¹í•˜ëŠ” í•µì‹¬ í”„ë¡œì„¸ì„œ
"""


import os
import torch
from fastapi import APIRouter, HTTPException, Query, Depends
from sqlalchemy.orm import Session, joinedload
from models import Measure, Client, User, BodyComposition, BloodPressure, HeartRate, Schedule, WeeklyReport
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from openai import OpenAI
import json
import httpx
import time
from core.config import settings
from schemas.health_data import HealthDataResponse
import aiohttp  # ë°°ì¹˜ëª¨ë“œì—ì„œ ì„¸ì…˜ ì¬ì‚¬ìš©ìš©
from openai import AsyncOpenAI  # ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel



class HealthDataProcessor:


    def __init__(self, db: Session):
        self.db = db


        self.offload_dir = "/tmp/offload_dir"
        os.makedirs(self.offload_dir, exist_ok = True)


        # ëª¨ë¸ ê²½ë¡œ (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
        self.model_path = os.getenv("BASE_MODEL_PATH", "/srv/models/base")
        self.adapter_path = os.getenv("ADAPTER_PATH", "/srv/models/mistral_lora_adapter")

        # ëª¨ë¸ ë¡œë”©
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
        base_model = AutoModelForCausalLM.from_pretrained(
            self.model_path,
            device_map="auto",
            torch_dtype=torch.float16,
            offload_folder="/tmp/offload_dir"  # offload_dir ëŒ€ì‹  offload_folder ì‚¬ìš©
        )
        self.model = PeftModel.from_pretrained(
            base_model,
            self.adapter_path,
            device_map = "auto",
            offload_folder = self.offload_dir)
        self.model.eval()  # í‰ê°€ ëª¨ë“œ

        # ë¹„ë™ê¸° OpenAI í´ë¼ì´ì–¸íŠ¸
        self.openai_client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)

         # ë°°ì¹˜ ì‘ì—…ìš© ì„¤ì •
        self.batch_mode = False
        self.aiohttp_session = None



    def set_batch_mode(self, enabled: bool, aiohttp_session: Optional[aiohttp.ClientSession] = None):
        """ë°°ì¹˜ ëª¨ë“œ ì„¤ì •"""
        self.batch_mode = enabled
        self.aiohttp_session = aiohttp_session



    async def collect_health_data(self, client_id: int, user_id: int) -> Dict:
        """ê±´ê°• ì¸¡ì • ë°ì´í„° ìˆ˜ì§‘"""
        today = datetime.now()
        start = today - timedelta(days=6)  # days ì˜¤íƒ€ ìˆ˜ì •

        # ë‚ ì§œ ë²”ìœ„ë¥¼ Epoch(ms)ë¡œ ë³€í™˜
        start_epoch = int(start.replace(hour=0, minute=0, second=0, microsecond=0).timestamp() * 1000)
        end_epoch = int((today - timedelta(days=1)).replace(hour=23, minute=59, second=59, microsecond=999000).timestamp() * 1000)

        # ì¡°íšŒ: ì›”~ê¸ˆ ë²”ìœ„ ë‚´ ì¸¡ì •
        measures = (
            self.db.query(Measure)
            .options(
                joinedload(Measure.body_composition),
                joinedload(Measure.blood_pressure),
                joinedload(Measure.heart_rate),
                joinedload(Measure.client)
            )
            .filter(
                Measure.user_id == user_id,
                Measure.client_id == client_id,
                Measure.date >= start_epoch,
                Measure.date <= end_epoch
            )
            .order_by(Measure.date.asc())
            .all()
        )

        # ë°ì´í„° í¬ë§· ë³€í™˜
        dm_list = []
        for measure in measures:
            bc = measure.body_composition
            bp = measure.blood_pressure
            hr = measure.heart_rate
            client = measure.client

            dm_item = {
                # ë‚ ì§œ
                "d": datetime.fromtimestamp(measure.date/1000).date().isoformat(),

                # body_composition ë°ì´í„° (None ì²´í¬)
                "bf": bc.bfp if bc else None,
                "mm": bc.smm if bc else None,
                "bw": bc.bfm if bc else None,  # ì‰¼í‘œ ëˆ„ë½ ìˆ˜ì •
                "prot": bc.protein if bc else None,
                "min": bc.mineral if bc else None,

                # client ë°ì´í„° (ì†ì„± ì ‘ê·¼ ë°©ì‹ ìˆ˜ì •)
                "wt": client.weight if client else None,
                "ht": client.height if client else None,

                # heart_rate ë°ì´í„°
                "hr": hr.bpm if hr else None,
                "o2": hr.oxygen if hr else None,

                # blood_pressure ë°ì´í„° (None ì²´í¬ ì¶”ê°€)
                "sys": bp.sbp if bp else None,
                "dia": bp.dbp if bp else None,
            }
            dm_list.append(dm_item)

        return {
            "ws": start.date().isoformat(),
            "we": (today - timedelta(days=1)).date().isoformat(),  # ë©”ì†Œë“œ í˜¸ì¶œ ìˆ˜ì •
            "dm": dm_list
        }





    async def call_internal_ai(self, health_data: Dict) -> Dict:
        """HuggingFace Mistral ëª¨ë¸(EC2ì— ì €ì¥ ì¤‘)ë¡œ ì§ì ‘ ì¶”ë¡ """

        prompt = {
            "input": (
                "### ì§ˆë¬¸:\n" + json.dumps(health_data, ensure_ascii=False) +
                "\n### ì§€ì‹œì‚¬í•­:\n1) ì£¼ê°„ í‰ê· Â·ìµœì†ŒÂ·ìµœëŒ“ê°’ì„ **wsum** í•„ë“œì— ì‘ì„±í•˜ê³ \n"
                "2) í‰ê·  ëŒ€ë¹„ Â±2 % ì´ìƒ ë²—ì–´ë‚œ ê°’ì„ **anom** ë°°ì—´ì—\n"
                "   { \"d\": ë‚ ì§œ, \"m\": ì§€í‘œ, \"v\": ê°’, \"pct\": Â±ë³€ë™ë¥  } í˜•ì‹ìœ¼ë¡œ ê¸°ë¡í•˜ë©°\n"
                "3) **cmt.g** ì—ì„œ\n"
                "   - ì£¼ê°„ ì´í‰ í•œ ë¬¸ë‹¨ ì‘ì„±\n"
                "   - íŠ¹ì´ì‚¬í•­ ë‚ ì§œÂ·ì§€í‘œÂ·Â±% ìš”ì•½\n"
                "4) ë³€ë™ ì§€í‘œì— ë§ì¶° 3ê°€ì§€ **fd**(ì‹ë‹¨) ì¶”ì²œ:\n"
                "   Â· ì²´ì¤‘Â·ì²´ì§€ë°© â†‘ â‡’ ì €ì§€ë°© ë©”ë‰´\n"
                "   Â· í˜ˆì•• â†‘ â‡’ ì €ì—¼ ë©”ë‰´\n"
                "(ê·¸ ì™¸ í•„ë“œëŠ” ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”)\n### ë‹µë³€:\n"
            )
        }

        # ğŸ”¹ Tokenize & Model Inference
        prompt_text = prompt["input"]  # ë¬¸ìì—´ë§Œ ì¶”ì¶œ
        inputs = self.tokenizer(prompt_text, return_tensors="pt").to(self.model.device)

        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=2048,
                do_sample=True,
                temperature=0.7
            )

        output_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # ğŸ”¹ JSON ë¶€ë¶„ë§Œ íŒŒì‹±
        if "### ë‹µë³€:" in output_text:
             json_part = output_text.split("### ë‹µë³€:")[1].strip()
             print("json_part : ", json_part)
        else:
             json_part = output_text.strip()
            #  print("json_part : ", json_part)
                
        return self.clean_ai_output(json_part)
 

         # ë°°ì¹˜ ëª¨ë“œì—ì„œëŠ” ì„¸ì…˜ ì¬ì‚¬ìš©
        if self.batch_mode and self.aiohttp_session:
            async with self.aiohttp_session.post(
                self.internal_ai_url,
                json=input_payload,
                timeout=aiohttp.ClientTimeout(total=30)
            ) as response:
                response.raise_for_status()
                return await response.json()
        else:
            # ë‹¨ì¼ ìš”ì²­ ëª¨ë“œ
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    self.internal_ai_url,
                    json=input_payload,
                    timeout=30.0
                )
                response.raise_for_status()
                return response.json()




    def clean_ai_output(self, ai_output: str) -> Dict:
        """AI output ì •ì œ"""
        try:
            # ë¬¸ìì—´ì´ ì•„ë‹Œ dictì¸ ê²½ìš° ì²˜ë¦¬
            if isinstance(ai_output, dict):
                return ai_output

            # JSON ë¬¸ìì—´ íŒŒì‹±
            if ai_output.startswith('"') and ai_output.endswith('"'):
                # JSON ë¬¸ìì—´ì´ ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ê²½ìš°
                ai_output = ai_output[1:-1]
                ai_output = ai_output.replace('\\"', '"')

            print("ai_output : ", ai_output)
            return json.loads(ai_output)

        except json.JSONDecodeError as e:
            raise HTTPException(status_code=500, detail=f"AI output íŒŒì‹± ì‹¤íŒ¨: {str(e)}")




    async def get_journal_data(self, client_id: int, user_id: int) -> List[Dict]:
        """ì¼ì§€ ë°ì´í„° ì¡°íšŒ"""
        today = datetime.now()
        start = today - timedelta(days=6)  # days ì˜¤íƒ€ ìˆ˜ì •

        # ë‚ ì§œ ë²”ìœ„ë¥¼ Epoch(ms)ë¡œ ë³€í™˜
        start_epoch = int(start.replace(hour=0, minute=0, second=0, microsecond=0).timestamp() * 1000)
        end_epoch = int((today - timedelta(days=1)).replace(hour=23, minute=59, second=59, microsecond=999000).timestamp() * 1000)

        schedules = (
            self.db.query(Schedule)
            .filter(
                Schedule.user_id == user_id,
                Schedule.client_id == client_id,
                Schedule.visited_date >= start_epoch,
                Schedule.visited_date <= end_epoch,
                Schedule.log_content.isnot(None)  # ì¼ì§€ê°€ ìˆëŠ” ê²ƒë§Œ
            )
            .order_by(Schedule.visited_date.asc())
            .all()
        )

        return [
            {
                "date": datetime.fromtimestamp(schedule.visited_date / 1000).date().isoformat(),
                "start_time": datetime.fromtimestamp(schedule.start_at / 1000).strftime("%H:%M") if schedule.start_at else None,
                "end_time": datetime.fromtimestamp(schedule.end_at / 1000).strftime("%H:%M") if schedule.end_at else None,
                "log_content": schedule.log_content or ""
            }
            for schedule in schedules
        ]





    def create_openai_prompt(self, ai_summary: Dict, journal_data: List) -> str:
        """OpenAI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # AI ìš”ì•½ ë°ì´í„° í¬ë§·íŒ…
        wsum = ai_summary.get("wsum", {})
        anomalies = ai_summary.get("anom", [])
        ai_comment = ai_summary.get("cmt", {}).get("g", "")
        food_suggestions = ai_summary.get("fd", [])

        # ëŒë´„ ì¼ì§€ ë°ì´í„° í¬ë§·íŒ…
        journal_summary = ""
        if journal_data:
            journal_entries = []
            for entry in journal_data[:5]:
                date = entry.get('date', '')
                content = entry.get('log_content', '')
                journal_entries.append(f"{date}: {content}")
            journal_summary = " | ".join(journal_entries)

        input_data = {
        "wsum": wsum,
        "anom": anomalies,
        "ai_comment": ai_comment,
        "food": food_suggestions,
        "journal": journal_summary
        }

        prompt = (
            "### ì§ˆë¬¸:\n" + json.dumps(input_data, ensure_ascii=False) + "\n"
            "### ì§€ì‹œì‚¬í•­:\n"
            "1) ì‘ë‹µì€ ë°˜ë“œì‹œ `report_content`, `fd_explain`, `journal_summary` ì„¸ ê°€ì§€ í‚¤ë¥¼ í¬í•¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
            "2) `report_content` í•„ë“œì—ëŠ” ì•„ë˜ **ë³´ê³ ì„œ í…œí”Œë¦¿**ê³¼ **100% ë˜‘ê°™ì€** bullet í¬ë§·ì„ ì‘ì„±í•˜ì„¸ìš”.\n"
            "3) `fd_explain` í•„ë“œì—ëŠ” ì¶”ì²œ ì‹ë‹¨ í•­ëª©ë³„ ì„¤ëª…ì„ í¬í•¨í•˜ì„¸ìš”.\n"
            "4) `journal_summary` í•„ë“œì—ëŠ” ì œê³µëœ journal ë°ì´í„° ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.\n"
            "5) ì‘ë‹µì€ ì ˆëŒ€ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë¥¼ ì„ì§€ ë§ê³ , **ìˆœìˆ˜ JSON** í˜•íƒœë¡œë§Œ ì œê³µí•˜ì„¸ìš”.\n\n"
            "```txt\n"
            "â€¢  ì£¼ê°„ ìš”ì•½\n"
            "- í‰ê·  ì²´ì§€ë°© : 17.07 %\n"
            "- í‰ê·  ì²´ì¤‘ : 66.88 kg\n"
            "- í‰ê·  ì‹¬ë°•ìˆ˜ : 69.01 bpm\n"
            "- í‰ê·  í˜ˆì•• : 128 / 78 mmHg\n\n"
            "â€¢  íŠ¹ì´ ë³€ë™\n"
            "- 2024-10-21 ì²´ì§€ë°©ì´ í‰ê· ë³´ë‹¤ â–² 2.7% ë†’ìŠµë‹ˆë‹¤\n"
            "- 2024-10-25 ì²´ì§€ë°©ì´ í‰ê· ë³´ë‹¤ â–² 3.3% ë†’ìŠµë‹ˆë‹¤\n"
            "- 2024-10-25 ì²´ë‚´ìˆ˜ë¶„ì´ í‰ê· ë³´ë‹¤ â–² 1.3% ë†’ìŠµë‹ˆë‹¤\n"
            "- 2024-10-25 ì´ì™„ê¸° í˜ˆì••ì´ í‰ê· ë³´ë‹¤ â–¼ 0.8% ë‚®ìŠµë‹ˆë‹¤\n"
            "- 2024-10-25 ì‹¬ë°•ìˆ˜ê°€ í‰ê· ë³´ë‹¤ â–¼ 3.9% ë†’ìŠµë‹ˆë‹¤\n"
            "- 2024-10-25 ìˆ˜ì¶•ê¸° í˜ˆì••ì´ í‰ê· ë³´ë‹¤ â–¼ 1.0% ë‚®ìŠµë‹ˆë‹¤\n\n"
            "â€¢ ì´í‰ \n"
            "- ì „ë°˜ì ìœ¼ë¡œ ê±´ê°• ì§€í‘œê°€ ì–‘í˜¸í•˜ë‚˜, ì‹¬ë°•ìˆ˜ì™€ í˜ˆì••ì— ì•½ê°„ì˜ ë³€ë™ì´ ìˆìŠµë‹ˆë‹¤. \n"
            "- ì „ë°˜ì ìœ¼ë¡œ ê±´ê°• ìƒíƒœë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•œ ì‹ë‹¨ ì¡°ì ˆì´ í•„ìš”í•©ë‹ˆë‹¤. \n\n"
            "â€¢ ì¶”ì²œ ì‹ë‹¨ \n"
            "- ë‹­ê°€ìŠ´ì‚´ ìƒëŸ¬ë“œ\n"
            " Â· ë‹¨ë°±ì§ˆì´ í’ë¶€í•˜ê³  ì €ì¹¼ë¡œë¦¬ ì‹ì‚¬ë¡œ, ì²´ì¤‘ ê´€ë¦¬ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.\n"
            "- í˜„ë¯¸ë°¥ê³¼ ëœì¥êµ­\n"
            " Â· ìœ ì‚°ê· ê³¼ í•­ì‚°í™” ë¬¼ì§ˆì´ í’ë¶€í•˜ì—¬ ë©´ì—­ë ¥ í–¥ìƒì— ë„ì›€ì´ ë©ë‹ˆë‹¤.\n"
            "- ê·€ë¦¬ ì˜¤íŠ¸ë°€\n"
            " Â· ì™„ì „ ë‹¨ë°±ì§ˆê³¼ ë¯¸ë„¤ë„ì´ í’ë¶€í•˜ì—¬ ê·¼ìœ¡ ìœ ì§€ì— ì¢‹ìŠµë‹ˆë‹¤.\n\n"
            "â€¢ ì¼ì§€ ìš”ì•½\n"
            "- ì‹ì‚¬ ì‹œê°„ì´ ë¶ˆê·œì¹™í•˜ê³ , ì €ë…ì— ê³¼ì‹í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.\n"
            "- ê±°ë™ì— ë¶ˆí¸í•¨ì´ ìˆì—ˆìœ¼ë‚˜ ì¬í™œ ìš´ë™ì„ í†µí•´ ê°œì„ ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
            "- ì‹ ì²´ í™œë™ëŸ‰ì´ ê°ì†Œí•˜ì—¬ ê°€ë²¼ìš´ ìŠ¤íŠ¸ë ˆì¹­ì„ ê¶Œì¥í–ˆìŠµë‹ˆë‹¤.\n"
            "```\n\n"
            "### ì‘ë‹µ í˜•ì‹:\n"
            "```json\n"
            "{\n"
            '  \"report_content\": \"â€¢  ì£¼ê°„ ìš”ì•½\\n- í‰ê·  ì²´ì§€ë°© : 17.07 %\\nâ€¦(ìœ„ í…œí”Œë¦¿ ê·¸ëŒ€ë¡œ)\\n\",\n"'
            '  \"fd_explain\": { \"ë‹­ê°€ìŠ´ì‚´\": \"â€¦\", \"í˜„ë¯¸ë°¥\": \"â€¦\", \"ê·€ë¦¬ ì˜¤íŠ¸ë°€\": \"â€¦\" },\n'
            '  \"journal_summary\": \"ì¼ì§€ ë°ì´í„° ìš”ì•½(ë‚ ì§œëŠ” ì ì§€ë§ˆ)\"\n'
            "}\n"
            "```\n\n"
            "ì£¼ì˜: ë°˜ë“œì‹œ ìœ„ ì„¸ ê°€ì§€ í‚¤(`report_content`, `fd_explain`, `journal_summary`)ë¥¼ ëª¨ë‘ í¬í•¨í•œ JSONë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.\n"
        )

        return prompt





    async def call_openai(self, ai_summary: Dict, journal_data: List) -> Dict:
        """OpenAI API í˜¸ì¶œ"""



        prompt = self.create_openai_prompt(ai_summary, journal_data)
        response = await self.openai_client.chat.completions.create(
                                                                model="gpt-4o-mini",
                                                                messages=[{"role":"user","content":prompt}],
                                                                temperature=0.7 )
        openai_output = response.choices[0].message.content.strip()

        # JSON ì•ë’¤ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
        if "```json" in openai_output:
            openai_output = openai_output.split("```json")[1].split("```")[0].strip()
        elif "```" in openai_output:
            openai_output = openai_output.split("```")[1].strip()

        # JSON íŒŒì‹± ì‹œë„
        try:
            print("openai_output",  openai_output)
            result = json.loads(openai_output)
        except json.JSONDecodeError as e:
            raise HTTPException(status_code=500, detail=f"OpenAI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")


        return result



    def save_to_database(self, client_id: int, user_id: int, ai_summary: Dict, openai_result: Dict) -> int:
        """ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""

        report_text =  openai_result.get('report_content', '')

        weekly_report = WeeklyReport(
            client_id=client_id,
            report_content=json.dumps(report_text, ensure_ascii=False),
            log_summary=openai_result.get('journal_summary', ''),
            created_at=int(time.time() * 1000)
        )

        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        self.db.add(weekly_report)
        self.db.commit()
        self.db.refresh(weekly_report)

        return weekly_report.report_id




