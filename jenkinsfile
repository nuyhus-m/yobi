// pipeline {
//     agent any

//     environment {
//         # Í≥†Ï†ïÍ∞í (ÎØºÍ∞êÌïòÏßÄ ÏïäÏùÄ Í∞í)
//         POSTGRES_USER = 's209'
//         POSTGRES_DB = 'yobi'
//         TZ = 'Asia/Seoul'
//         SPRING_REDIS_HOST = 'redis'
//         SPRING_REDIS_PORT = '6379'
//         SPRING_REDIS_DB = '0'
//         REDIS_HOST = 'redis'
//         REDIS_PORT = '6379'
//         REDIS_DB = '0'
//         DATABASE_URL = 'postgresql://postgres:s209password@localhost:5432/S209'
//         INTERNAL_AI_URL = 'http://localhost:8001/ai/analyze'
//         BASE_MODEL_PATH = '/srv/models/base'
//         ADAPTER_PATH = '/srv/models/mistral_lora_adapter'
//         MERGED_MODEL_PATH = '/srv/models/merged'
//         HF_CACHE_DIR = '/srv/models/cache'
//         BATCH_MAX_WORKERS = '20'
//         BATCH_MAX_CONCURRENT = '10'
//         LOG_LEVEL = 'INFO'
//         LOG_PATH = '/app/logs'

//         # ÎØºÍ∞êÏ†ïÎ≥¥ (Jenkins CredentialsÏóêÏÑú Í∞ÄÏ†∏Ïò§Í∏∞)
//         HF_TOKEN = credentials('hf_token')
//         OPENAI_API_KEY = credentials('openai_api_key')
//         POSTGRES_PASSWORD = credentials('postgres_password')
//         SPRING_REDIS_PASSWORD = credentials('redis_password')
//         REDIS_PASSWORD = credentials('redis_password')
//     }

//     stages {
//         stage('Check & Download Mistral LoRA') {
//             steps {
//                 script {
//                     def modelCheck = sh(script: "[ -f ${BASE_MODEL_PATH}/config.json ] && [ -f ${ADAPTER_PATH}/adapter_model.bin ]", returnStatus: true)

//                     if (modelCheck != 0) {
//                         echo "üîç Î™®Îç∏Ïù¥ ÏóÜÏùå. download_models.py Ïã§Ìñâ"
//                         sh """
//                         // JenkinsÍ∞Ä ÎÑòÍ∏¥ HF_TOKENÎ•º ÌòÑÏû¨ Ïâò ÌôòÍ≤ΩÎ≥ÄÏàòÎ°ú Îì±Î°ù
//                             export HF_TOKEN=${HF_TOKEN}
//                             export BASE_MODEL_PATH=${BASE_MODEL_PATH}
//                             export ADAPTER_PATH=${ADAPTER_PATH}
//                             export HF_HOME=${HF_CACHE_DIR}
//                             export TEST_MODEL_LOADING=true
//                             python3 scripts/download_models.py
//                         """
//                     } else {
//                         echo "‚úÖ Î™®Îç∏Ïù¥ Ïù¥ÎØ∏ Ï°¥Ïû¨Ìï©ÎãàÎã§. Îã§Ïö¥Î°úÎìú Ïä§ÌÇµ"
//                     }
//                 }
//             }
//         }

//         stage('Build & Deploy AI App') {
//             steps {
//                 sh 'docker-compose -f docker-compose.yml up -d --build'
//             }
//         }
//     }
// }
