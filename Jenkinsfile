pipeline {
    agent any

    /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê³µí†µ í™˜ê²½ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
    environment {
        /* Git ì €ì¥ì†Œ ë‚´ë¶€ ê²½ë¡œ */
        DOCKER_CTX   = "AI"              // build context
        DOCKERFILE   = "AI/Dockerfile"   // Dockerfile ê²½ë¡œ

        /* ì›ê²©(2ë²ˆ) ê²½ë¡œ */
        REMOTE_PATH  = "/home/ubuntu/S12P31S209"    // composeÂ·.env ìœ„ì¹˜
        COMPOSE_FILE = "/home/ubuntu/S12P31S209/docker-compose.ec2-2.yml"

        /* Docker Hub ì´ë¯¸ì§€ */
        DOCKER_IMAGE = "mundevelop/ai-app:latest"

        /* ëª¨ë¸ ê²½ë¡œ (ì»¨í…Œì´ë„ˆÂ·í˜¸ìŠ¤íŠ¸ ê³µí†µ) */
        BASE_MODEL_PATH = "/srv/models/base"
        ADAPTER_PATH    = "/srv/models/mistral_lora_adapter"
        HF_CACHE_DIR    = "/srv/models/cache"

        /* Jenkins Credentials */
        EC2_AI_IP       = "43.203.38.182"           // 2ë²ˆ ì„œë²„ IP
    }

    stages {
        /* 0. ì›Œí¬ìŠ¤í˜ì´ìŠ¤ í™•ì¸ (ì˜µì…˜) */
        stage('Check Workspace') {
            steps {
                sh 'echo "[Workspace] $WORKSPACE"'
                sh 'pwd && ls -al'
            }
        }

        /* 1. ai-dev ë¸Œëœì¹˜ì¸ì§€ í™•ì¸ */
        stage('Branch Check') {
            steps {
                script {
                    def branch = env.BRANCH_NAME ?: env.GIT_BRANCH?.replaceFirst(/^origin\//,'') ?: 'unknown'
                    if (!branch.contains('ai-dev')) {
                        echo "âŒ ai-dev ì „ìš© íŒŒì´í”„ë¼ì¸. í˜„ì¬: ${branch}"
                        currentBuild.result = 'SUCCESS'
                        error('ai-dev ê°€ ì•„ë‹ˆë¼ì„œ ì¤‘ë‹¨')
                    }
                    echo "âœ… ai-dev ë¸Œëœì¹˜ í™•ì¸ ì™„ë£Œ"
                }
            }
        }

        /* 2. ì½”ë“œ ì²´í¬ì•„ì›ƒ */
        stage('Checkout') {
            steps { checkout scm }
        }

        /* 2-A. requirements.txt ì—ì„œ psycopg2 ì œê±° */
        stage('Patch requirements (drop psycopg2)') {
            steps {
                sh '''
                  sed -i -E '/^psycopg2(-binary)?([[:space:]]*==.*)?[[:space:]]*$/Id' AI/requirements.txt
                  echo "== after patch =="
                  grep -n psycopg2 AI/requirements.txt || echo "âœ” no psycopg2 lines"
                '''
            }
        }

        /* 3. .env íŒŒì¼ ì¤€ë¹„ (Jenkins íŒŒì¼-credential) */
        stage('Prepare .env') {
            steps {
                withCredentials([file(credentialsId: 'ai-env-secret', variable: 'ENV_SRC')]) {
                    sh 'cp $ENV_SRC .env'
                }
            }
        }

        /* 4. Docker ì´ë¯¸ì§€ ë¹Œë“œ */
        stage('Build Docker Image') {
            steps {
                sh """
                export DOCKER_BUILDKIT=0        # BuildKit OFF
                docker build --pull --no-cache \
                            -f ${DOCKERFILE} \
                            -t ${DOCKER_IMAGE} \
                            ${DOCKER_CTX}
                """
            }
        }

        /* 5. Docker Hub Push */
        stage('Push Docker Image') {
            steps {
                withCredentials([usernamePassword(
                    credentialsId: 'docker-hub-creds',
                    usernameVariable: 'HUB_USER',
                    passwordVariable: 'HUB_PASS'
                )]) {
                    sh '''
                        echo "$HUB_PASS" | docker login -u "$HUB_USER" --password-stdin
                        docker push ${DOCKER_IMAGE}
                        docker logout
                    '''
                }
            }
        }

        stage('Deploy to AI Server') {
            steps {
                sshagent(credentials: ['ec2-2-pem-key-id']) {
                    withCredentials([string(credentialsId: 'hf_token', variable: 'HF_TOKEN')]) {
                        sh """
                        ssh -o StrictHostKeyChecking=no ubuntu@${EC2_AI_IP} bash -c "
                        set -e

                        echo ğŸ“¦ Pulling Docker Image: ${DOCKER_IMAGE}
                        docker pull ${DOCKER_IMAGE}

                        sudo mkdir -p ${BASE_MODEL_PATH} ${ADAPTER_PATH} ${HF_CACHE_DIR}
                        sudo chown -R ubuntu:ubuntu /srv/models

                        if [ ! -f ${BASE_MODEL_PATH}/config.json ] || [ ! -f ${ADAPTER_PATH}/adapter_model.bin ]; then
                            echo â¬‡ï¸ Downloading Models
                            docker run --rm \\
                                -e HF_TOKEN=${HF_TOKEN} \\
                                -v /srv/models:/srv/models \\
                                -v /mnt/data/huggingface:/root/.cache/huggingface \\
                                ${DOCKER_IMAGE} \\
                                python app/ai_model/download_models.py
                        fi

                        echo ğŸš€ Deploying via docker-compose
                        docker-compose -f ${COMPOSE_FILE} --env-file ${REMOTE_PATH}/.env up -d --build --force-recreate"
                        """
                    }
                }
            }
        }
    }
}
